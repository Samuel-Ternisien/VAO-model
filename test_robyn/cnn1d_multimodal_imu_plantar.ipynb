{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN 1D multimodal (IMU + Plantar)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "Device: cuda\n",
            "GPU: NVIDIA RTX 6000 Ada Generation\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", device)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def smart_read_csv(path):\n",
        "    for sep in [\";\", \"\\t\", \",\"]:\n",
        "        try:\n",
        "            df = pd.read_csv(path, sep=sep)\n",
        "            if df.shape[1] > 1:\n",
        "                return df\n",
        "        except Exception:\n",
        "            pass\n",
        "    raise ValueError(f\"Impossible de lire {path}\")\n",
        "\n",
        "\n",
        "def find_time_col(df):\n",
        "    for c in df.columns:\n",
        "        if \"time\" in c.lower():\n",
        "            return c\n",
        "    raise ValueError(\"Colonne temps non trouvee\")\n",
        "\n",
        "\n",
        "def read_and_slice_by_time(path, t0, t1):\n",
        "    df = smart_read_csv(path)\n",
        "    tcol = find_time_col(df)\n",
        "\n",
        "    df = df[(df[tcol] >= t0) & (df[tcol] <= t1)]\n",
        "    df = df.drop(columns=[tcol])\n",
        "\n",
        "    return torch.tensor(df.values, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def resample_to_L(x, L):\n",
        "    \"\"\"\n",
        "    x : [T, C] -> [L, C]\n",
        "    \"\"\"\n",
        "    T, C = x.shape\n",
        "\n",
        "    if T == 0:\n",
        "        return torch.zeros(L, C)\n",
        "\n",
        "    if T == L:\n",
        "        return x\n",
        "\n",
        "    idx = torch.linspace(0, T - 1, L)\n",
        "    idx0 = idx.long()\n",
        "    idx1 = torch.clamp(idx0 + 1, max=T - 1)\n",
        "    w = idx - idx0\n",
        "\n",
        "    return (1 - w).unsqueeze(1) * x[idx0] + w.unsqueeze(1) * x[idx1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOTS = {\n",
        "    \"imu\": \"/home/fisa/stockage1/mindscan/IMU\",\n",
        "    \"plantar\": \"/home/fisa/stockage1/mindscan/Plantar_activity\",\n",
        "    \"events\": \"/home/fisa/stockage1/mindscan/Events\",\n",
        "}\n",
        "\n",
        "FILENAMES = {\n",
        "    \"imu\": \"imu.csv\",\n",
        "    \"plantar\": \"insoles.csv\",\n",
        "}\n",
        "\n",
        "L = 256\n",
        "NUM_CLASSES = 31\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total segments: 10204\n"
          ]
        }
      ],
      "source": [
        "def build_segments_index(events_root):\n",
        "    rows = []\n",
        "    subjects = sorted([\n",
        "        d for d in os.listdir(events_root)\n",
        "        if os.path.isdir(os.path.join(events_root, d))\n",
        "    ])\n",
        "\n",
        "    for subject in subjects:\n",
        "        for seq in os.listdir(os.path.join(events_root, subject)):\n",
        "            classif = os.path.join(events_root, subject, seq, \"classif.csv\")\n",
        "            if not os.path.exists(classif):\n",
        "                continue\n",
        "\n",
        "            df = pd.read_csv(classif, sep=\";\")\n",
        "            for _, r in df.iterrows():\n",
        "                rows.append({\n",
        "                    \"subject\": subject,\n",
        "                    \"seq\": seq,\n",
        "                    \"label\": int(r[\"Class\"]),\n",
        "                    \"t0\": float(r[\"Timestamp Start\"]),\n",
        "                    \"t1\": float(r[\"Timestamp End\"]),\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "segments = build_segments_index(ROOTS[\"events\"])\n",
        "print(\"Total segments:\", len(segments))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train segments: 6084\n",
            "Val segments: 1569\n"
          ]
        }
      ],
      "source": [
        "allowed_subjects = {f\"S{str(i).zfill(2)}\" for i in range(1, 25)}\n",
        "segments = segments[segments[\"subject\"].isin(allowed_subjects)].reset_index(drop=True)\n",
        "\n",
        "subjects = sorted(segments[\"subject\"].unique())\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(subjects)\n",
        "\n",
        "n_train = int(0.8 * len(subjects))\n",
        "train_subjects = set(subjects[:n_train])\n",
        "val_subjects = set(subjects[n_train:])\n",
        "\n",
        "train_segments = segments[segments[\"subject\"].isin(train_subjects)].reset_index(drop=True)\n",
        "val_segments = segments[segments[\"subject\"].isin(val_subjects)].reset_index(drop=True)\n",
        "\n",
        "print(\"Train segments:\", len(train_segments))\n",
        "print(\"Val segments:\", len(val_segments))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiModalEventDataset(Dataset):\n",
        "    def __init__(self, segments_df, roots, filenames, L=256):\n",
        "        self.df = segments_df.reset_index(drop=True)\n",
        "        self.roots = roots\n",
        "        self.filenames = filenames\n",
        "        self.L = L\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        subject, seq = r[\"subject\"], r[\"seq\"]\n",
        "        t0, t1 = float(r[\"t0\"]), float(r[\"t1\"])\n",
        "        y = int(r[\"label\"]) - 1\n",
        "\n",
        "        imu_path = os.path.join(self.roots[\"imu\"], subject, seq, self.filenames[\"imu\"])\n",
        "        plantar_path = os.path.join(self.roots[\"plantar\"], subject, seq, self.filenames[\"plantar\"])\n",
        "\n",
        "        imu = read_and_slice_by_time(imu_path, t0, t1)            # [T, 96]\n",
        "        imu = resample_to_L(imu, self.L).transpose(0, 1).contiguous()  # [96, 256]\n",
        "\n",
        "        plantar = read_and_slice_by_time(plantar_path, t0, t1)    # [T, C]\n",
        "        plantar = resample_to_L(plantar, self.L).transpose(0, 1).contiguous()  # [C, 256]\n",
        "\n",
        "        return {\n",
        "            \"imu\": imu,\n",
        "            \"plantar\": plantar,\n",
        "            \"y\": torch.tensor(y, dtype=torch.long),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train batch IMU: torch.Size([128, 96, 256])\n",
            "Train batch Plantar: torch.Size([128, 50, 256])\n",
            "Train batch y: torch.Size([128])\n",
            "Channels -> IMU: 96 | Plantar: 50\n"
          ]
        }
      ],
      "source": [
        "train_ds = MultiModalEventDataset(train_segments, ROOTS, FILENAMES, L)\n",
        "val_ds = MultiModalEventDataset(val_segments, ROOTS, FILENAMES, L)\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "val_dl = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    num_workers=8,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "b = next(iter(train_dl))\n",
        "imu_channels = b[\"imu\"].shape[1]\n",
        "plantar_channels = b[\"plantar\"].shape[1]\n",
        "print(\"Train batch IMU:\", b[\"imu\"].shape)\n",
        "print(\"Train batch Plantar:\", b[\"plantar\"].shape)\n",
        "print(\"Train batch y:\", b[\"y\"].shape)\n",
        "print(\"Channels -> IMU:\", imu_channels, \"| Plantar:\", plantar_channels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvBranch(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, 64, 7, stride=2, padding=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 128, 5, stride=2, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x.mean(dim=-1)  # [B, 256]\n",
        "\n",
        "\n",
        "class IMUPlantarMultiCNN(nn.Module):\n",
        "    def __init__(self, imu_in_channels=96, plantar_in_channels=32, num_classes=31):\n",
        "        super().__init__()\n",
        "        self.imu_branch = ConvBranch(imu_in_channels)\n",
        "        self.plantar_branch = ConvBranch(plantar_in_channels)\n",
        "\n",
        "        # Fusion multilayer des deux representations [256 + 256]\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, imu_x, plantar_x):\n",
        "        imu_feat = self.imu_branch(imu_x)\n",
        "        plantar_feat = self.plantar_branch(plantar_x)\n",
        "        fused = torch.cat([imu_feat, plantar_feat], dim=1)\n",
        "        return self.classifier(fused)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_multimodal(model, train_dl, val_dl, epochs=20, lr=1e-3):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = total = 0\n",
        "\n",
        "        pbar = tqdm(train_dl, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        for batch in pbar:\n",
        "            imu_x = batch[\"imu\"].to(device, non_blocking=True)\n",
        "            plantar_x = batch[\"plantar\"].to(device, non_blocking=True)\n",
        "            y = batch[\"y\"].to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(imu_x, plantar_x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * imu_x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            total += imu_x.size(0)\n",
        "\n",
        "            pbar.set_postfix(\n",
        "                loss=f\"{running_loss / total:.4f}\",\n",
        "                acc=f\"{correct / total:.3f}\",\n",
        "            )\n",
        "\n",
        "        model.eval()\n",
        "        val_correct = val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dl:\n",
        "                imu_x = batch[\"imu\"].to(device)\n",
        "                plantar_x = batch[\"plantar\"].to(device)\n",
        "                y = batch[\"y\"].to(device)\n",
        "                logits = model(imu_x, plantar_x)\n",
        "                val_correct += (logits.argmax(1) == y).sum().item()\n",
        "                val_total += y.size(0)\n",
        "\n",
        "        print(f\"Val acc: {val_correct / val_total:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5: 100%|██████████| 48/48 [04:23<00:00,  5.48s/it, acc=0.290, loss=2.4598] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 0.549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5:  79%|███████▉  | 38/48 [02:46<00:30,  3.01s/it, acc=0.632, loss=1.1416]"
          ]
        }
      ],
      "source": [
        "model = IMUPlantarMultiCNN(\n",
        "    imu_in_channels=imu_channels,\n",
        "    plantar_in_channels=plantar_channels,\n",
        "    num_classes=NUM_CLASSES,\n",
        ").to(device)\n",
        "\n",
        "train_multimodal(model, train_dl, val_dl, epochs=5, lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/fisa/pirosa/test_robyn/cnn1d_multimodal_imu_plantar.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.167.254.21/home/fisa/pirosa/test_robyn/cnn1d_multimodal_imu_plantar.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m             total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m y\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.167.254.21/home/fisa/pirosa/test_robyn/cnn1d_multimodal_imu_plantar.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m correct \u001b[39m/\u001b[39m total\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B194.167.254.21/home/fisa/pirosa/test_robyn/cnn1d_multimodal_imu_plantar.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m val_acc \u001b[39m=\u001b[39m evaluate(model, val_dl)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.167.254.21/home/fisa/pirosa/test_robyn/cnn1d_multimodal_imu_plantar.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValidation accuracy (IMU + Plantar): \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            imu_x = batch[\"imu\"].to(device)\n",
        "            plantar_x = batch[\"plantar\"].to(device)\n",
        "            y = batch[\"y\"].to(device)\n",
        "\n",
        "            logits = model(imu_x, plantar_x)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "val_acc = evaluate(model, val_dl)\n",
        "print(f\"Validation accuracy (IMU + Plantar): {val_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = val_ds[0]\n",
        "imu_x = sample[\"imu\"].unsqueeze(0).to(device)\n",
        "plantar_x = sample[\"plantar\"].unsqueeze(0).to(device)\n",
        "y_true = sample[\"y\"].item()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(imu_x, plantar_x)\n",
        "    y_pred = logits.argmax(dim=1).item()\n",
        "\n",
        "print(\"Vrai label :\", y_true)\n",
        "print(\"Label predit :\", y_pred)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
